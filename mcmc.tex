% to-do
% -----
% - write zeroth draft
% - write first draft
% - send to friendlies for comments
%   - Brewer
%   - Lang
%   - Rix
%   - Bovy
% - post on arXiv

% style notes
% -----------
% - [LaTeX] newline after every full stop for proper git diffing
% - [LaTeX] eqnarray not equation
% - pdf not PDF

\documentclass[12pt,twoside,pdftex]{article}
\usepackage{styles/dar_endnotes}

\newcommand{\this}{Using Markov Chain Monte Carlo}
\include{styles/dar}

\newcommand{\data}{D}
\newcommand{\pars}{\theta}

\begin{document}

\thispagestyle{plain}\raggedbottom
\section*{Data analysis recipes:\\ \this\footnotemark}

\footnotetext{%
    The notes begin on page~\pageref{note:first}, including the
    license\note{\label{note:first}
        Copyright 2013 by the authors. This work is licensed under a
        \href{http://creativecommons.org/licenses/by-nc-nd/3.0/deed.en\_US}{%
            Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported
            License}.}
    and the acknowledgements\note{%
        We would like to thank
          Jo Bovy (IAS),
          Brendon Brewer (Auckland),
          Jonathan Goodman (NYU),
          Fengji Hou (NYU), and
          Dustin Lang (CMU)
        for valuable advice and comments.}.
}

\noindent
Dan~Foreman-Mackey\\
\affil{Center~for~Cosmology~and~Particle~Physics, Department~of~Physics,%
       New York University}
\\[1ex]
David~W.~Hogg\\
\affil{Center~for~Cosmology~and~Particle~Physics, Department~of~Physics,%
       New York University}\\
\affil{Max-Planck-Institut f\"ur Astronomie, Heidelberg}

\begin{abstract}
Markov Chain Monte Carlo (MCMC) methods for sampling probability
distribution functions, plus abundant computational resources,
have transformed
the sciences.
Here we give a fast overview of basic MCMC methods and then turn to
practical advice for their use in real inference problems.
We give advice on method choice, tuning for performance,
initialization and burn-in, judging convergence, and use of the chain
output to make results {\it with error bars}.
% ******* BJB
% Giving MCMC results with error bars is uncommon, but cool. I thought it
% deserved an italic
[Insert some generally useful point here!]
\end{abstract}

\section{When do you need MCMC?}

Markov Chain Monte Carlo (MCMC) methods are methods for sampling
probability distribution functions (pdfs). These pdfs may be either probability
mass functions on a discrete space, or probability densities on a continuous
space.
% ******* BJB
% pdf usually stands for probability density function. You are using non-standard
% terminology here. My words above might be too technical given the aim of your
% document.
They don't require that you have a full analytic description of the
properly normalized pdf for sampling to proceed; they only require
that you be able to compute ratios of the pdf at pairs of locations.
These properties make MCMC methods ideal for sampling \emph{posterior
  pdfs} in probabilistic inferences:
% ******** BJB
% I know you don't like it, but LOTS of people use and understand the word
% Bayesian.
In probabilistic inferences, the posterior pdf $p(\pars\given\data)$,
or pdf for the parameters $\pars$ given the data $\data$, is
constructed from the likelihood $p(\data\given\pars)$, or pdf for the
data given the parameters, and the prior pdf $p(\pars)$ for the
parameters by what's often known as ``Bayes rule'',
\begin{eqnarray}
p(\pars\given\data) &=& \frac{1}{Z}\,p(\data\given\pars)\,p(\pars)
\quad .
\end{eqnarray}
% ********* BJB
% Unfortunately there are many more names for the evidence. I prefer
% marginal likelihood myself.
In these contexts, the constant $Z$, sometimes written as
$p(\data)$, is known by the names ``evidence'', ``marginal likelihood''
the ``Bayes integral'' and ``prior predictive probability'', and is usually
\emph{extremely hard to
  calculate}.\note{Say words about why we call it $Z$ not $p(\data)$
  and why it is extremely hard to calculate.}
That is, you often know the function $p(\pars\given\data)$ up to a
constant factor; you can compute ratios of the pdf at pairs of points,
but not the precise value at any individual point.

In addition to this normalization-insensitive property of MCMC, in its
simplest forms it can be run without computing any derivatives or
integrals of the function, and (as we will show below) in its simplest
forms it is \emph{extremely easy to implement}.
For all these reasons, MCMC is ideal for sampling posterior pdfs in
the real situations in which scientists find themselves.

Say you are in this situation.
You have a huge blob of data $\data$ (think of this as a vector or
list or heterogeneous collection of observations\note{In general in
  this \documentname\ we will treat any variable as being capable of
  containing not just a value but some huge arbitrarily structured set
  of values in matrix, vector, or more complex form.}).
You also have a model sophisticated enough---a probabilistic,
generative model, if you will\note{For our definition of a
  \emph{model}, see [SOME OTHER NOTE] in this series.}---that, given a
setting of a huge blob of parameters $\pars$\note{Again, the parameter
  blob $\pars$ should also be thought of as an immense, arbitrarily
  structured set or list of parameters, possibly even with no fixed
  dimension!}, you can compute a pdf for data (or likelihood\note{We
  bash the terminology ``likelihood'' in [SOME OTHER NOTE] in this
  series.}) $p(\data\given\pars)$.
% ************* BJB
% <Wild Subjective Bayesian>
% The "generative model" is a probabilistic description of your *prior
% beliefs about what the data are going to be*. </Wild Subjective Bayesian>
And say you also can write down some kind of informative or
uninformative prior pdf $p(\pars)$ for the parameter blob.
If all these things are true, then---even if you can't compute
anything else---in principle a trivial-to-implement MCMC can give you
a fair sampling of the posterior pdf.
That is, you can run MCMC (for a very long time\note{A very, very long
  time; we will return to that below.}) and you will be left with a
set of $K$ parameter-blob settings $\pars_k$ such that the full set
$\setofall{\pars_k}_{k=1}^K$ constitutes a fair sampling from the
posterior pdf $p(\pars\given\data$).

All that said, and adhering to the traditions of the \project{Data
  Analysis Recipes} project\note{Every chapter in the \project{Data
    Analysis Recipes} series begins with a rant in which we argue that
  most uses of the methods in question are not appropriate!}, we are
compelled to note that MCMC is in fact \emph{over-used}.
Because MCMC provably (under assumptions\note{Hint at assumptions
  here.}, some of which will be discussed below) samples the full
posterior pdf in all of parameter space, many investigators use MCMC
because it will sample \emph{all} of the parameter space
($\pars$-space).
That is, they are using MCMC because they want to
\emph{search the parameter space for good models}.
Because MCMC samples the parameter representatively, it spends most of
its time near very good models; models that (within the confines of
the prior pdf) do a good job of explaining the data.
For this reason, many investigators are using MCMC because it
effectively \emph{optimizes the posterior pdf}.

Both of these reasons for using MCMC---that it is a parameter-space
search algorithm, and that it is a simple-to-code effective
optimizer---are \emph{not good reasons}.  MCMC is first and foremost a
\emph{sampler}.  If you are trying to find the optimum of the
likelihood or the posterior pdf, you should use an \emph{optimzer},
not a sampler.  If you want to make sure you search all of parameter
space, you should use a \emph{search algorithm}, not a sampler.  MCMC
is good at one thing, and one thing only: Sampling ill-normalized
pdfs.

\section{What is M--H MCMC?}

...The algorithm

...Why does it work (briefly)?

...What is a typical proposal distribution?

...You can't sample the likelihood!  You can only sample a posterior
pdf!

\section{stretch move and other variants}

...How does the stretch move work?

...Why is the stretch move useful?

...What, briefly, is nested sampling, and why is it good?

...What, briefly, is hamiltonian, and why is it good?

\section{Results, error bars, and figures}

...So you have a chain output, what do you do with it?

...What is the number and error bar?  What is an upper limit?

...What figures should you make to check the chain?

\section{Convergence}

...How do you know you have run long enough?  Heuristically...

...Autocorrelation time

\section{Tuning}

...How do you make it run fast?

...Acceptance ratio and ESJD and etc.

...Gibbs sampling and interior marginalizations

\section{Initialization and burn-in}

...Precede with optimization

...Start from different locations

...Dealing with multi-modal problems

\section{Advice and discussion}

...Write and debug your own M--H sampler and then download a real
package \emph{afterwards}.

...breaking Markov-ness.

...Initialization and burn-in advice we haven't addressed earlier?

...The Bayes integral / evidence integral?

...Posterior predictive checks?

...Finally, to repeat: You can't sample the likelihood!  You can only
sample a posterior pdf!

% \begin{figure}[htbp]
% \exampleplot{ex17}
% \caption{Partial solution to \problemname~\ref{prob:bayesintrinsic}:
% The marginalized posterior probability distribution for the intrinsic
% variance.}\label{fig:bayesintrinsic}
% \end{figure}

\clearpage
\markright{Notes}\theendnotes

\clearpage
\begin{thebibliography}{}\markright{References}
\bibitem[Foreman-Mackey et al.(2012)]{emcee}
  Foreman-Mackey,~D., Hogg,~D.~W., Lang,~D., \& Goodman,~J.\ 2012,
  \project{emcee}: The MCMC Hammer,
  \arxiv{1202.3665}
\end{thebibliography}

\end{document}
