% to-do
% -----
% - write zeroth draft
% - write first draft
% - send to friendlies for comments
%   - Lang
%   - Rix
%   - Bovy
% - post on arXiv

% style notes
% -----------
% - [LaTeX] newline after every full stop for proper git diffing
% - [LaTeX] eqnarray not equation
% - pdf not PDF
% - is it ``a MCMC sampling'' or ``an MCMC sampling''?

\documentclass[12pt,twoside,pdftex]{article}
\usepackage{styles/dar_endnotes}

\newcommand{\this}{Using Markov Chain Monte Carlo}
\include{styles/dar}

\newcommand{\data}{D}
\newcommand{\pars}{\theta}

\begin{document}

\thispagestyle{plain}\raggedbottom
\section*{Data analysis recipes:\\ \this\footnotemark}

\footnotetext{%
    The notes begin on page~\pageref{note:first}, including the
    license\note{\label{note:first}
        Copyright 2013 by the authors. This work is licensed under a
        \href{http://creativecommons.org/licenses/by-nc-nd/3.0/deed.en\_US}{%
            Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported
            License}.}
    and the acknowledgements\note{%
        We would like to thank
          Jo Bovy (IAS),
          Brendon Brewer (Auckland),
          Jonathan Goodman (NYU),
          Fengji Hou (NYU), and
          Dustin Lang (CMU)
        for valuable advice and comments.}.
}

\noindent
Dan~Foreman-Mackey\\
\affil{Center~for~Cosmology~and~Particle~Physics, Department~of~Physics,
       New York University}\\[1ex]
David~W.~Hogg\\
\affil{Center~for~Cosmology~and~Particle~Physics, Department~of~Physics,
       New York University}\\
\affil{Max-Planck-Institut f\"ur Astronomie, Heidelberg}

\begin{abstract}
Markov Chain Monte Carlo (MCMC) methods for sampling probability
distribution functions, plus abundant computational resources,
have transformed the sciences.
Here we give a fast overview of basic MCMC methods and then turn to
practical advice for their use in real inference problems.
We give advice on method choice, tuning for performance,
initialization and burn-in, judging convergence, and use of the chain
output to produce parameter estimates with associated uncertainties.
[Insert some generally useful point here!]
\end{abstract}

\section{When do you need MCMC?}

Markov Chain Monte Carlo (MCMC) methods are methods for sampling
probability distribution functions or probability density functions (pdfs).
These pdfs may be either probability mass functions on a discrete
space, or probability densities on a continuous space, though we will
concentrate on the latter in this \documentname.
MCMC methods don't require that you have a full analytic description of the
properly normalized pdf for sampling to proceed; they only require
that you be able to compute ratios of the pdf at pairs of locations.
This makes MCMC methods ideal for sampling \emph{posterior
  pdfs} in probabilistic inferences:

In a probabilistic inference, the posterior pdf $p(\pars\given\data)$,
or pdf for the parameters $\pars$ given the data $\data$, is
constructed from the likelihood $p(\data\given\pars)$, or pdf for the
data given the parameters, and the prior pdf $p(\pars)$ for the
parameters by what's often known as ``Bayes rule'',
\begin{eqnarray}
p(\pars\given\data) &=& \frac{1}{Z}\,p(\data\given\pars)\,p(\pars)
\quad .
\end{eqnarray}
In these contexts, the constant $Z$, sometimes written as
$p(\data)$, is known by the names ``evidence'', ``marginal likelihood''
the ``Bayes integral'' and ``prior predictive probability'', and is usually
\emph{extremely hard to
  calculate}.\note{Say words about why we call it $Z$ not $p(\data)$
  and why it is extremely hard to calculate.}
That is, you often know the function $p(\pars\given\data)$ up to a
constant factor; you can compute ratios of the pdf at pairs of points,
but not the precise value at any individual point.

In addition to this normalization-insensitive property of MCMC, in its
simplest forms it can be run without computing any derivatives or
integrals of the function, and (as we will show below) in its simplest
forms it is \emph{extremely easy to implement}.
For all these reasons, MCMC is ideal for sampling posterior pdfs in
the real situations in which scientists find themselves.

Say you are in this situation.
You have a huge blob of data $\data$ (think of this as a vector or
list or heterogeneous collection of observations\note{In general in
  this \documentname\ we will treat any variable as being capable of
  containing not just a value but some huge arbitrarily structured set
  of values in matrix, vector, or more complex form.}).
You also have a model sophisticated enough---a probabilistic,
generative model, if you will\note{For our definition of a
  \emph{model}, see [SOME OTHER NOTE] in this series.}---that, given a
setting of a huge blob of parameters\note{Again, the parameter
  blob $\pars$ should also be thought of as an immense, arbitrarily
  structured set or list of parameters, possibly even with no fixed
  dimension!} $\pars$, you can compute a pdf for data (or likelihood\note{We
  bash the terminology ``likelihood'' in [SOME OTHER NOTE] in this
  series.}) $p(\data\given\pars)$.
% ************* BJB
% <Wild Subjective Bayesian>
% The "generative model" is a probabilistic description of your *prior
% beliefs about what the data are going to be*. </Wild Subjective Bayesian>
% ************* Hogg
% That comment should go in the ``What is a Model?'' Chapter.
Furthermore, say you also can write down some kind of informative or
vague prior pdf $p(\pars)$ for the parameter blob.
If all these things are true, then---even if you can't compute
anything else---in principle a trivial-to-implement MCMC can give you
a fair sampling of the posterior pdf.
That is, you can run MCMC (for a very long time\note{Sometimes a very,
  very long time; we will return to that below.})  and you will be
left with a set of $K$ parameter-blob settings $\pars_k$ such that the
full set $\setofall{\pars_k}_{k=1}^K$ constitutes a fair sampling from
the posterior pdf $p(\pars\given\data$).
% ************* BJB
% Notions of "sampling" and "Monte Carlo" are interesting. You might like to
% refer the interested reader to the paper "Monte Carlo is Fundamentally
% Unsound" by Tony O'Hagan.

All that said, and adhering to the traditions of the \project{Data
  Analysis Recipes} project\note{Every chapter in the \project{Data
    Analysis Recipes} series begins with a rant in which we argue that
  most uses of the methods in question are not appropriate!}, we are
compelled to note that MCMC is in fact \emph{over-used}.
Because MCMC provably (under assumptions\note{Hint at assumptions
  here.}, some of which will be discussed below) samples the full
posterior pdf in all of parameter space, many investigators use MCMC
because it will sample \emph{all} of the parameter space
($\pars$-space).
That is, they are using MCMC because they want to
\emph{search the parameter space for good models}.
Because MCMC samples the parameter representatively, it spends most of
its time near very good models; models that (within the confines of
the prior pdf) do a good job of explaining the data.
For this reason, many investigators are using MCMC because it
effectively \emph{optimizes the posterior pdf}, or, for certain
choices of prior pdf, \emph{optimizes the likelihood}.\note{Of course
  a committed Bayesian would argue that any time you are optimizing a
  posterior pdf or optimizing a likelihood, you \emph{should} be
  sampling a posterior pdf.  That is, for some, the fact that when
  someone ``wants'' to optimize, it is actually useful that they
  choose the ``wrong'' tool, because that ``wrong'' tool gives them
  back something far more useful than the output of any optimizer!}

Both of these reasons for using MCMC---that it is a parameter-space
search algorithm, and that it is a simple-to-code effective
optimizer---are \emph{not good reasons}.  MCMC is first and foremost a
\emph{sampler}.  If you are trying to find the optimum of the
likelihood or the posterior pdf, you should use an \emph{optimzer},
not a sampler.  If you want to make sure you search all of parameter
space, you should use a \emph{search algorithm}, not a sampler.  MCMC
is good at one thing, and one thing only: Sampling ill-normalized (or
otherwise hard to sample) pdfs.

\section{What is a sampling?}

...What is a sampling, heurstically?.. Along the way, what is a pdf?..

If there is a pdf $p(x)$ for some quantity $x$, which can be a scalar
or a multi-element vector or list or blob, we can define
\emph{expectation values} $E[x]$ for $x$ or for any quantity that can
be expressed as a function $q(x)$ of $x$:
\begin{eqnarray}
E[x] &\equiv& \int x\,p(x)\,\dd x
\\
E[q] &\equiv& \int q(x)\,p(x)\,\dd x
\quad ,
\end{eqnarray}
where the integrals are implicitly definite integrals over the domain
of $x$ (all the parts of $x$ space in which $p(x)$ is finite) and the
integrals are multi-dimensional if $x$ is multi-dimensional.  These
expectation values are the mean values of $x$ and $q(x)$ under the
pdf.  A good sampling---really the definition of a good
sampling---makes the sampling approximation to these integrals
accurate.  With a good sampling $\setofall{x_k}_{k=1}^K$ the integrals
get replaced with sums over samples $x_k$:
\begin{eqnarray}
E[x] &\approx& \frac{1}{K}\,\sum_{k=1}^K x_k
\\
E[q] &\approx& \frac{1}{K}\,\sum_{k=1}^K q(x_k)
\quad .
\end{eqnarray}
That is, a sampling is good when any expectation value of interest is
accurately computed via the sampling approximation.  Your conditions
on your sampling will depend on the expectations you want to compute,
and the accuracies you need.

...How is the sampling of the marginalized pdf trivially constructed from the full sampling?..

...Is there any way to reconstruct $p(x)$ from the samples
$\setofall{x_k}$?  In short, no, but in many cases of interest, sort-of!..

...You can't sample the likelihood!  You can only sample a posterior
pdf!.. why not?.. Give a sense of the difficulties you get into if you
fail here; like discussion with Sven Kreiss on 2013-02-14...

\section{What is M--H MCMC?}

...The algorithm

...Why does it work (briefly)?

...What is a typical proposal distribution?

% *********** BJB
% YES!!!! Although you can sample the likelihood if your samples are in
% data space. :)

% *********** BJB
% I suggest partitioning the discussion of different methods into the following
% two categories:
%
%  i) Methods for getting around the target distribution
% ii) Methods that change the target distribution to something
% other than the posterior pdf, to help the sampling somehow
%
% i) Would include things like M-H, the stretch move,
% Hamiltonian, slice sampling (maybe skip the latter)
% ii) would include things like annealing and Nested Sampling

\section{stretch move and other variants}

...How does the stretch move work?

...Why is the stretch move useful?

...What, briefly, is nested sampling, and why is it good?

...What, briefly, is hamiltonian, and why is it good?

\section{Results, error bars, and figures}

For a committed probabilistic scientist---frequentist or
bayesian---there is no ``answer'', there are only probability density
functions.  Any time in a paper or in an email or in a conversation
we say what ``the answer is''---even if we say it with an error
bar---we have departed the probabilistic program.  There are many
principled ways to depart the program; in another \documentname, we
discuss the economic explanation of how we can make hard decisions in
the context of probabilistic reasoning\note{CITE DECISION DOCUMENT}.
But without going into the economic model, it is fair to say that a
substantial problem with being a committed probabilist is that when we
\emph{publish}, we are not permitted (not now, at least) to publish a
\emph{probability distribution over pubications}; we have to publish
\emph{one single, deterministic text}; we have to \emph{decide} what
to write in the title, the abstract, the tables, figures, and results
section.  Given a MCMC sampling of the posterior pdf, what do we
report as our \emph{results}?

...What should you report as the inferred parameter value and
associated uncertainty (error bar)?  What is an upper limit?  Do this
all for ONE DIMENSION.

...Now for multiple dimensions...return to the marginalization point
from above...

...What do you do in high-dimensional spaces?  Note the issue
that---even in a unimodal posterior PDF---the most probable model
might not be at the set of parameter values that are reported if you
compute the parameter values to report in one-dimensional projections
of the posterior pdf.  This requires a figure to demonstrate.  What to
do here?

...What figures should you make to display the chain?

...If you are really good, you will pass forward a sampling.  How big
should it be?  Refer to Mackay here.

\section{Convergence}

A key question for an MCMC operator---\emph{the} key question in some
sense---is \emph{how long to run} to be sure of having reliable
results.
It is disappointing and annoying to many that there is no extremely
simple and reliable answer to this question.

The reason that there is no simple answer is that you can't really
ever know that you have sampled the full posterior pdf, and the reason
for \emph{that} is that if you \emph{could} know that, you would also
be able to solve the famously difficult discrete optimization
problem.\note{explain this remark and cite something here}
Another way to put it is that you might have two modes---two separated
regions of substantial total probability---in the posterior pdf that
are both important but separated by a large region of low probability.
If you are using a simple sampler, you could sample one of these modes
very well but the sampler will take effectively infinite time to find
the other mode.
Any test of convergence would be passed, but in fact the sampling
would be incomplete and not representative.
That is, knowing that you have a complete and representative sampling
is nearly impossible.

Heuristically, however, you have sampled long enough when you can see
that the (or each) walker has traversed the high-probability parts of
the parameter space many times in the length of the chain.
Or, equivalently, you have sampled long enough when the first half of
the chain shows very much the same posterior pdf morphology as the
second half of the chain, or indeed as any substantial subset.

...What plot should you make?  Make plots that demonstrate a non-converged and a converged chain.

...Autocorrelation time is the premier tool.  It is not a panacea, and why?

\section{Tuning}

...How do you make it run fast?

...Acceptance ratio and ESJD and etc.

% BJB
% Please suggest mixtures of scales for M-H proposals.
% You can mimic the properties of slice sampling but with
% much easier code.

...Gibbs sampling and interior marginalizations

\section{Initialization and burn-in}

...Precede with optimization
% BJB
% If applicable. Bad idea in high dimension/underconstrained
% problem.

...Start from different locations
% BJB
% What different locations?
% Drawn from the prior can be useful. Then you can
% look at the chains and see which ones "made it" and
% which ones "got stuck" and delete the latter

...Dealing with multi-modal problems
% Starting from different locations is good
% for DIAGNOSING a problem as multimodal but it's
% terrible for quantifying the modes. Explain why,
% it's a good teaching point.

\section{Advice and discussion}

...Write and debug your own M--H sampler and then download a real
package \emph{afterwards}.
% ***** BJB
% I AGREE WHOLEHEARTEDLY. That's how to learn.

...breaking Markov-ness.
% ***** BJB
% "Diminishing adaptations" is an idea that is quite easy
% to explain. There are other ways to break Markov-ness but
% this probably covers enough of them for an intro document
% ***** Hogg
% I was going to say you should NEVER break Markov-ness
% unless you REALLY understand what you are doing.

...Initialization and burn-in advice we haven't addressed earlier?

...The Bayes integral / evidence integral?

...Posterior predictive checks?

...Finally, to repeat: You can't sample the likelihood!  You can only
sample a posterior pdf!

% \begin{figure}[htbp]
% \exampleplot{ex17}
% \caption{Partial solution to \problemname~\ref{prob:bayesintrinsic}:
% The marginalized posterior probability distribution for the intrinsic
% variance.}\label{fig:bayesintrinsic}
% \end{figure}

\clearpage
\markright{Notes}\theendnotes

\clearpage
\begin{thebibliography}{}\markright{References}
\bibitem[Foreman-Mackey et al.(2012)]{emcee}
  Foreman-Mackey,~D., Hogg,~D.~W., Lang,~D., \& Goodman,~J.\ 2012,
  \project{emcee}: The MCMC Hammer,
  \arxiv{1202.3665}
\end{thebibliography}

\end{document}
